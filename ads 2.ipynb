{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import randint as sp_randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                  41          880           129.0   \n",
      "1    -122.22     37.86                  21         7099          1106.0   \n",
      "2    -122.24     37.85                  52         1467           190.0   \n",
      "3    -122.25     37.85                  52         1274           235.0   \n",
      "4    -122.25     37.85                  52         1627           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0         322         126         8.3252              452600        NEAR BAY  \n",
      "1        2401        1138         8.3014              358500        NEAR BAY  \n",
      "2         496         177         7.2574              352100        NEAR BAY  \n",
      "3         558         219         5.6431              341300        NEAR BAY  \n",
      "4         565         259         3.8462              342200        NEAR BAY  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  int64  \n",
      " 3   total_rooms         20640 non-null  int64  \n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  int64  \n",
      " 6   households          20640 non-null  int64  \n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  int64  \n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('housing.csv')\n",
    "\n",
    "# Check data\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data.drop(columns=['median_house_value'])\n",
    "y = data['median_house_value']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: Train RMSE = 68433.93736666226, Test RMSE = 70031.4878994794\n",
      "Random Forest: Train RMSE = 18057.87746223084, Test RMSE = 48970.98700871799\n",
      "Gradient Boosting: Train RMSE = 52901.31388484858, Test RMSE = 55961.91083557595\n",
      "SVR: Train RMSE = 118406.21946397949, Test RMSE = 116917.38986872014\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "# Train models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    train_pred = model.predict(X_train_processed)\n",
    "    test_pred = model.predict(X_test_processed)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "    print(f\"{name}: Train RMSE = {train_rmse}, Test RMSE = {test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "55 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.81211933        nan        nan 0.76686917        nan        nan\n",
      " 0.81715351 0.80201916 0.80718267 0.80976771 0.80112598        nan\n",
      " 0.80976016        nan 0.76636265        nan        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "Best Score for Random Forest: 0.8171535068004298\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Random Forest (Reduced search space)\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for Random Forest (Fewer iterations)\n",
    "rf_random = RandomizedSearchCV(RandomForestRegressor(), param_distributions=param_dist_rf, n_iter=20, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "rf_random.fit(X_train_processed, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters for Random Forest:\", rf_random.best_params_)\n",
    "print(\"Best Score for Random Forest:\", rf_random.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Pipeline: Train RMSE = 13814.253543982799, Test RMSE = 49566.30870079155\n"
     ]
    }
   ],
   "source": [
    "# Define pipeline with optimized Random Forest\n",
    "pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', rf_random.best_estimator_)])\n",
    "\n",
    "# Train pipeline\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate pipeline\n",
    "train_pred_rf = pipeline_rf.predict(X_train)\n",
    "test_pred_rf = pipeline_rf.predict(X_test)\n",
    "train_rmse_rf = np.sqrt(mean_squared_error(y_train, train_pred_rf))\n",
    "test_rmse_rf = np.sqrt(mean_squared_error(y_test, test_pred_rf))\n",
    "print(\"Random Forest Pipeline: Train RMSE = {}, Test RMSE = {}\".format(train_rmse_rf, test_rmse_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model: Train RMSE = 52901.31388484858, Test RMSE = 55963.50954443141\n"
     ]
    }
   ],
   "source": [
    "# Ensemble model\n",
    "ensemble_model = GradientBoostingRegressor()\n",
    "ensemble_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Predictions\n",
    "train_pred_ensemble = ensemble_model.predict(X_train_processed)\n",
    "test_pred_ensemble = ensemble_model.predict(X_test_processed)\n",
    "\n",
    "# Evaluation\n",
    "train_rmse_ensemble = np.sqrt(mean_squared_error(y_train, train_pred_ensemble))\n",
    "test_rmse_ensemble = np.sqrt(mean_squared_error(y_test, test_pred_ensemble))\n",
    "print(\"Ensemble Model: Train RMSE = {}, Test RMSE = {}\".format(train_rmse_ensemble, test_rmse_ensemble))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
